{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已知时程数据$Y$和$Y$，两者有线性关系：\n",
    "\n",
    "$$\n",
    "Y=AX\n",
    "$$\n",
    "\n",
    "尝试改用PyTorch梯度下降，通过线性回归，求$A$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑一个简单的无偏置的线性回归问题。对于\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_1 & = a_{11} x_1+ a_{21} x_2 +\\cdots +a_{n1} x_n \\\\\n",
    "& = \\begin{bmatrix} x_{1} & x_{2} & \\cdots & x_{n} \\end{bmatrix}\n",
    "\\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{n1} \\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "若共有$T$对$\\{x_i\\}$和$y_1$的组合，则有：\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} y_1(1) \\\\ y_1(2) \\\\ \\vdots \\\\ y_1(T) \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_{1}(1) & x_{2}(1) & \\cdots & x_{n}(1) \\\\\n",
    "x_{1}(2) & x_{2}(2) & \\cdots & x_{n}(2) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{1}(T) & x_{2}(T) & \\cdots & x_{n}(T)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{n1} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "因此，若继续引入更多$\\{y_i\\}$，则有：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\n",
    "\\begin{bmatrix}\n",
    "y_{1}(1) & y_{2}(1) & \\cdots & y_{m}(1) \\\\\n",
    "y_{1}(2) & y_{2}(2) & \\cdots & y_{m}(2) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "y_{1}(T) & y_{2}(T) & \\cdots & y_{m}(T)\n",
    "\\end{bmatrix}_{T \\times m} & =\n",
    "\\begin{bmatrix}\n",
    "x_{1}(1) & x_{2}(1) & \\cdots & x_{n}(1) \\\\\n",
    "x_{1}(2) & x_{2}(2) & \\cdots & x_{n}(2) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{1}(T) & x_{2}(T) & \\cdots & x_{n}(T)\n",
    "\\end{bmatrix}_{T \\times n}\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1m} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nm}\n",
    "\\end{bmatrix}_{n \\times m} \\\\\n",
    "\n",
    "\\Rightarrow\n",
    "Y_{T \\times m} & = X_{T \\times n} A_{n \\times m}\n",
    "\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，由于$X$和$Y$在行方向表示时间上的演化，需要将问题转变为如下形式，方便通过**PyTorch**搭建单层的神经网络实现线性回归：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y & = A X \\\\\n",
    "\\Rightarrow\n",
    "Y^{H} & = X^{H} A^{H}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "只需要先线性回归出$A^{H}$，再共轭转置即可得到结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 选择训练设备\n",
    "def get_device(device=0):\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = f\"cuda:{device}\"\n",
    "        if torch.cuda.device_count() > device:\n",
    "            return device_name\n",
    "        else:\n",
    "            print(f\"No such cuda device: {device}\")\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "# 定义网络结果\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "# 定义训练函数\n",
    "def trainer(\n",
    "    model, train_loader, num_epochs, optimizer, loss_type=nn.MSELoss(), device=0\n",
    "):\n",
    "    print(\"PyTorch Version:\", torch.__version__)\n",
    "    device = get_device(device)\n",
    "    print(\"Training on\", device)\n",
    "    print(\n",
    "        \"====================================Start training====================================\"\n",
    "    )\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        with tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"\n",
    "        ) as t:\n",
    "            for x, y in t:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(x)\n",
    "                loss = loss_type(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "    print(\n",
    "        \"====================================Finish training====================================\\n\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单输入单输出线性回归示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Training on cuda:0\n",
      "====================================Start training====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 100/100 [00:03<00:00, 25.47batch/s, loss=4.52e+5]\n",
      "Epoch 2/10: 100%|██████████| 100/100 [00:00<00:00, 332.71batch/s, loss=1.1e+5]\n",
      "Epoch 3/10: 100%|██████████| 100/100 [00:00<00:00, 392.57batch/s, loss=1.25e+4]\n",
      "Epoch 4/10: 100%|██████████| 100/100 [00:00<00:00, 351.23batch/s, loss=2.64e+3]\n",
      "Epoch 5/10: 100%|██████████| 100/100 [00:00<00:00, 373.59batch/s, loss=152]\n",
      "Epoch 6/10: 100%|██████████| 100/100 [00:00<00:00, 332.70batch/s, loss=5.79]\n",
      "Epoch 7/10: 100%|██████████| 100/100 [00:00<00:00, 428.69batch/s, loss=0.646]\n",
      "Epoch 8/10: 100%|██████████| 100/100 [00:00<00:00, 394.14batch/s, loss=0.717]\n",
      "Epoch 9/10: 100%|██████████| 100/100 [00:00<00:00, 378.53batch/s, loss=0.342]\n",
      "Epoch 10/10: 100%|██████████| 100/100 [00:00<00:00, 350.15batch/s, loss=0.393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================Finish training====================================\n",
      "\n",
      "A =\n",
      " [[1.9978443]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练数据\n",
    "X = torch.linspace(1, 1000, 1000).reshape(-1, 1)\n",
    "y = torch.linspace(2, 2000, 1000).reshape(-1, 1)\n",
    "\n",
    "# 数据加载器\n",
    "train_data = TensorDataset(X, y)\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "\n",
    "# 模型\n",
    "model1 = LinearRegression(1, 1)\n",
    "\n",
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01, weight_decay=0)\n",
    "trainer(\n",
    "    model1,\n",
    "    train_loader,\n",
    "    num_epochs=10,\n",
    "    optimizer=optimizer,\n",
    "    loss_type=nn.MSELoss(),\n",
    "    device=0,\n",
    ")\n",
    "\n",
    "WEIGHT = model1.linear.weight.detach().cpu()\n",
    "WEIGHT = WEIGHT.numpy()\n",
    "print(\"A =\\n\", WEIGHT)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多输入单输出示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Training on cuda:0\n",
      "====================================Start training====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 200/200 [00:00<00:00, 590.72batch/s, loss=12.6]\n",
      "Epoch 2/30: 100%|██████████| 200/200 [00:00<00:00, 541.71batch/s, loss=3.13] \n",
      "Epoch 3/30: 100%|██████████| 200/200 [00:00<00:00, 555.52batch/s, loss=1.27] \n",
      "Epoch 4/30: 100%|██████████| 200/200 [00:00<00:00, 574.44batch/s, loss=0.53] \n",
      "Epoch 5/30: 100%|██████████| 200/200 [00:00<00:00, 543.17batch/s, loss=1.02] \n",
      "Epoch 6/30: 100%|██████████| 200/200 [00:00<00:00, 561.88batch/s, loss=1.42] \n",
      "Epoch 7/30: 100%|██████████| 200/200 [00:00<00:00, 574.03batch/s, loss=0.876]\n",
      "Epoch 8/30: 100%|██████████| 200/200 [00:00<00:00, 552.63batch/s, loss=0.38] \n",
      "Epoch 9/30: 100%|██████████| 200/200 [00:00<00:00, 490.18batch/s, loss=0.893] \n",
      "Epoch 10/30: 100%|██████████| 200/200 [00:00<00:00, 562.36batch/s, loss=0.352] \n",
      "Epoch 11/30: 100%|██████████| 200/200 [00:00<00:00, 534.37batch/s, loss=0.26]  \n",
      "Epoch 12/30: 100%|██████████| 200/200 [00:00<00:00, 528.12batch/s, loss=0.152] \n",
      "Epoch 13/30: 100%|██████████| 200/200 [00:00<00:00, 598.26batch/s, loss=0.0924]\n",
      "Epoch 14/30: 100%|██████████| 200/200 [00:00<00:00, 546.14batch/s, loss=0.104]  \n",
      "Epoch 15/30: 100%|██████████| 200/200 [00:00<00:00, 586.63batch/s, loss=0.082]  \n",
      "Epoch 16/30: 100%|██████████| 200/200 [00:00<00:00, 482.60batch/s, loss=0.0362] \n",
      "Epoch 17/30: 100%|██████████| 200/200 [00:00<00:00, 545.28batch/s, loss=0.00371]\n",
      "Epoch 18/30: 100%|██████████| 200/200 [00:00<00:00, 570.91batch/s, loss=0.00864]\n",
      "Epoch 19/30: 100%|██████████| 200/200 [00:00<00:00, 547.20batch/s, loss=0.00878] \n",
      "Epoch 20/30: 100%|██████████| 200/200 [00:00<00:00, 586.40batch/s, loss=0.00213] \n",
      "Epoch 21/30: 100%|██████████| 200/200 [00:00<00:00, 559.96batch/s, loss=0.000851]\n",
      "Epoch 22/30: 100%|██████████| 200/200 [00:00<00:00, 496.39batch/s, loss=0.00085] \n",
      "Epoch 23/30: 100%|██████████| 200/200 [00:00<00:00, 532.19batch/s, loss=0.000139]\n",
      "Epoch 24/30: 100%|██████████| 200/200 [00:00<00:00, 544.82batch/s, loss=3.08e-5] \n",
      "Epoch 25/30: 100%|██████████| 200/200 [00:00<00:00, 565.69batch/s, loss=2.14e-5]\n",
      "Epoch 26/30: 100%|██████████| 200/200 [00:00<00:00, 539.09batch/s, loss=4.58e-6]\n",
      "Epoch 27/30: 100%|██████████| 200/200 [00:00<00:00, 581.27batch/s, loss=7.99e-7]\n",
      "Epoch 28/30: 100%|██████████| 200/200 [00:00<00:00, 580.82batch/s, loss=1.55e-7]\n",
      "Epoch 29/30: 100%|██████████| 200/200 [00:00<00:00, 525.11batch/s, loss=2.84e-8]\n",
      "Epoch 30/30: 100%|██████████| 200/200 [00:00<00:00, 588.67batch/s, loss=2.48e-9] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================Finish training====================================\n",
      "\n",
      "A =\n",
      " [[2.9999115 7.9998837]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练数据\n",
    "X1 = torch.rand(1000, 1).reshape(-1, 1)\n",
    "X2 = torch.rand(1000, 1).reshape(-1, 1)\n",
    "X = torch.concatenate((X1, X2), axis=1)\n",
    "y = (3 * X1 + 8 * X2).reshape(-1, 1)\n",
    "\n",
    "# 数据加载器\n",
    "train_data = TensorDataset(X, y)\n",
    "train_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
    "\n",
    "# 模型\n",
    "model2 = LinearRegression(2, 1)\n",
    "\n",
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01, weight_decay=0)\n",
    "trainer(\n",
    "    model2,\n",
    "    train_loader,\n",
    "    num_epochs=30,\n",
    "    optimizer=optimizer,\n",
    "    loss_type=nn.MSELoss(),\n",
    "    device=0,\n",
    ")\n",
    "\n",
    "WEIGHT = model2.linear.weight.detach().cpu()\n",
    "WEIGHT = WEIGHT.numpy()\n",
    "print(\"A =\\n\", WEIGHT)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多输入多输出示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.1\n",
      "Training on cuda:0\n",
      "====================================Start training====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 200/200 [00:00<00:00, 269.52batch/s, loss=3.68] \n",
      "Epoch 2/30: 100%|██████████| 200/200 [00:00<00:00, 296.43batch/s, loss=0.772]\n",
      "Epoch 3/30: 100%|██████████| 200/200 [00:00<00:00, 318.36batch/s, loss=1.18] \n",
      "Epoch 4/30: 100%|██████████| 200/200 [00:00<00:00, 359.80batch/s, loss=0.544]\n",
      "Epoch 5/30: 100%|██████████| 200/200 [00:00<00:00, 333.59batch/s, loss=0.742]\n",
      "Epoch 6/30: 100%|██████████| 200/200 [00:00<00:00, 357.93batch/s, loss=0.512]\n",
      "Epoch 7/30: 100%|██████████| 200/200 [00:00<00:00, 358.21batch/s, loss=0.478] \n",
      "Epoch 8/30: 100%|██████████| 200/200 [00:00<00:00, 312.34batch/s, loss=0.255] \n",
      "Epoch 9/30: 100%|██████████| 200/200 [00:00<00:00, 358.85batch/s, loss=0.0756]\n",
      "Epoch 10/30: 100%|██████████| 200/200 [00:00<00:00, 336.18batch/s, loss=0.144] \n",
      "Epoch 11/30: 100%|██████████| 200/200 [00:00<00:00, 378.21batch/s, loss=0.116] \n",
      "Epoch 12/30: 100%|██████████| 200/200 [00:00<00:00, 326.37batch/s, loss=0.0753]\n",
      "Epoch 13/30: 100%|██████████| 200/200 [00:00<00:00, 342.16batch/s, loss=0.125]  \n",
      "Epoch 14/30: 100%|██████████| 200/200 [00:00<00:00, 327.30batch/s, loss=0.0627] \n",
      "Epoch 15/30: 100%|██████████| 200/200 [00:00<00:00, 309.77batch/s, loss=0.0427] \n",
      "Epoch 16/30: 100%|██████████| 200/200 [00:00<00:00, 345.69batch/s, loss=0.00796]\n",
      "Epoch 17/30: 100%|██████████| 200/200 [00:00<00:00, 303.26batch/s, loss=0.0142] \n",
      "Epoch 18/30: 100%|██████████| 200/200 [00:00<00:00, 356.37batch/s, loss=0.013]   \n",
      "Epoch 19/30: 100%|██████████| 200/200 [00:00<00:00, 330.67batch/s, loss=0.00329] \n",
      "Epoch 20/30: 100%|██████████| 200/200 [00:00<00:00, 334.30batch/s, loss=0.00199] \n",
      "Epoch 21/30: 100%|██████████| 200/200 [00:00<00:00, 313.28batch/s, loss=0.000252]\n",
      "Epoch 22/30: 100%|██████████| 200/200 [00:00<00:00, 341.22batch/s, loss=0.000585]\n",
      "Epoch 23/30: 100%|██████████| 200/200 [00:00<00:00, 325.61batch/s, loss=0.000183]\n",
      "Epoch 24/30: 100%|██████████| 200/200 [00:00<00:00, 353.03batch/s, loss=1.4e-5]  \n",
      "Epoch 25/30: 100%|██████████| 200/200 [00:00<00:00, 335.66batch/s, loss=1.9e-6] \n",
      "Epoch 26/30: 100%|██████████| 200/200 [00:00<00:00, 349.32batch/s, loss=4.35e-6]\n",
      "Epoch 27/30: 100%|██████████| 200/200 [00:00<00:00, 361.73batch/s, loss=3.72e-7]\n",
      "Epoch 28/30: 100%|██████████| 200/200 [00:00<00:00, 305.23batch/s, loss=4.38e-7]\n",
      "Epoch 29/30: 100%|██████████| 200/200 [00:00<00:00, 377.08batch/s, loss=4.54e-8]\n",
      "Epoch 30/30: 100%|██████████| 200/200 [00:00<00:00, 347.14batch/s, loss=5.8e-9]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================Finish training====================================\n",
      "\n",
      "A =\n",
      " [[2.9997127  7.9996257 ]\n",
      " [4.999993   3.9999979 ]\n",
      " [1.9999995  0.99999994]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练数据\n",
    "X1 = torch.rand(1000, 1).reshape(-1, 1)\n",
    "X2 = torch.rand(1000, 1).reshape(-1, 1)\n",
    "X = torch.concatenate((X1, X2), axis=1)\n",
    "y1 = (3 * X1 + 8 * X2).reshape(-1, 1)\n",
    "y2 = (5 * X1 + 4 * X2).reshape(-1, 1)\n",
    "y3 = (2 * X1 + 1 * X2).reshape(-1, 1)\n",
    "y = torch.concatenate((y1, y2, y3), axis=1)\n",
    "\n",
    "# 数据加载器\n",
    "train_data = TensorDataset(X, y)\n",
    "train_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
    "\n",
    "# 模型\n",
    "model3 = LinearRegression(2, 3)\n",
    "\n",
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=0.01, weight_decay=0)\n",
    "trainer(\n",
    "    model3,\n",
    "    train_loader,\n",
    "    num_epochs=30,\n",
    "    optimizer=optimizer,\n",
    "    loss_type=nn.MSELoss(),\n",
    "    device=0,\n",
    ")\n",
    "\n",
    "WEIGHT = model3.linear.weight.detach().cpu()\n",
    "WEIGHT = WEIGHT.numpy()\n",
    "print(\"A =\\n\", WEIGHT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoopmanControlSystem",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
